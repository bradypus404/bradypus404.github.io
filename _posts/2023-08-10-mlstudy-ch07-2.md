---
layout: post
title: "[ML Study]ch07-2 심층 신경망"
subtitle: 혼자 공부하는 머신러닝+딥러닝 [7-2]
date: 2023-08-09 09:02:00 +0900
author: Hyeonsu
categories: [Machine Learning]
tags: [심층 신경망, 렐루 함수, 옵티마이저]
---
<body>
    <img
    src="/assets/images/post/book_banner.jpg"
    align="right"
    width="20%"
    height="27.2%"
    />
    <br><br>
    <p>본 포스팅 한빛미디어의 <a href="https://product.kyobobook.co.kr/detail/S000001810330"><혼자공부하는 머신러닝+딥러닝(박해선 저)></a>를 요약 정리했습니다.</p>
</body>
<br>

### 1. 2개의 층 
---------------------------

케라스 API를 사용해 MNIST 데이터셋을 불러온다.
1절과 같이 학습시키고 인공 신경망 모델에 층을 2개 추가한다.

입력층과 출력층 사이에 밀집층이 추가된 것으로, 이 사이에 있는 모든 층을 **은닉층**이라 부른다.
은닉층에는 주황색 원으로 활성화 함수가 표시되는데,
활성화 함수는 신경망 층의 선형 방정식의 계산 값에 적용하는 함수로 출력층에 적용하는 활성화 함수보다 비교적 자유롭다.

은닉층에서 선형적인 산술 계산만 수행한다면 수행 역할이 없는 셈이 되어 선형 계산을 적당하게 비선형적으로 비틀어야 한다.
다음 층의 계산과 단순히 합쳐지는 것을 방지하고 나름의 역할을 하도록 하는 것이다.

많이 사용하는 활성화 함수 중 하나는 **시그모이드 함수**이다.

이 함수는 뉴런의 출력을 z값을 0과 1 사이로 압축하는데
시그모이드 활성화 함수를 사용한 은닉층과 소프트맥스 함수를 사용한 출력층을 케라스의 Dense 클래스로 만들어 보자.

```python
dense1 = keras.layers.Dense(100, activation='sigmod', input_shape=(784,))
dense2 = keras.layers.Dense(10, activation='softmax')
```
dense1이 은닉층이고 100개의 뉴런을 가진 밀집층이다. 
은닉층의 뉴런 개수를 정하는데는 특별한 기준이 없다.
하지만 적어도 출력층의 뉴런보다는 많게 만들어야 한다. 부족한 정보가 전달될 수 있기 때문이다.
dense2는 출력층으로 10개의 클래스를 분류하므로 10개의 뉴런을 둔 것이다.

### 2. 심층 신경망 만들기  
---------------------------

앞서 만든 두 객체를 Sequential클래스에 추가해서 **심층 신경망**을 만들어 보자.

```pyhton
model = keras.Sequential([dense1, dense2])
```
이때 여러 개의 층을 추가하려면 두 객체를 리스트로 만들어 전달해야 한다.
이 리스트는 가장 처음 등장하는 은닉층에서 마지막 출력층의 순서로 나열하여 가장 마지막에 두어야 한다.

케라스는 모델의 summary() 메서드를 호출하면 층에 대한 유용한 정보를 얻을 수 있는데 
```pyhton
model.summary()
```
이런 식으로 확인 가능하다.

맨 첫 줄에 모델 이름이 나오면서 이 모델에 들어 잇는 층이 순서대로 나열된다.
층마다 층 이름, 클래스, 출력 크기, 모델 파라미터 개수가 출력되는 것을 볼 수 있다.

