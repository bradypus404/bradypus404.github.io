---
layout: post
title: "[ML Study]ch01-3 마켓과 머신러닝"
subtitle: 혼자 공부하는 머신러닝+딥러닝 [1-3]
date: 2023-07-05 09:01:00 +0900
author: Hyemin
categories: [Machine Learning]
tags: [특성, 훈련, K-최근접 이웃 알고리즘, 모델, 정확도]
---

### 마켓과 머신러닝
------------------
#### 이진 분류
머신러닝에서 여러 개의 종류(혹은 `클래스(class)`) 중 하나를 구별해 내는 문제를 `분류(classification)` 라고 부른다.

2개의 클래스 중 하나를 고르는 문제를 `이진 분류(binary classification)` 라고 한다.

-------------------
#### 산점도
`산점도(scaatter plot)`는 x, y축으로 이뤄진 좌표계에 두 변수(x, y)의 관계를 표현하는 방법이다.

`맷플롯립(matplotlib)`은 파이썬에서 과학계산용 그래프를 그리는 대표적인 패키지이다.

`임포트(import)`는 따로 만들어둔 파이썬 패키지(클래스와 함수의 묶음)를 사용하기 위해 불러오는 명령이다.

-------------------    
#### 산점도 그리기
```python
bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]
bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]
```

- 데이터의 `특성(feature)` 리스트이다.
    - `특성`은 데이터를 표현하는 하나의 성질이다. 

```python
import matplotlib.pyplot as plt

plt.scatter(bream_length, bream_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

- 산점도를 그리기 위해 먼저 import로 matplotlib 패키지를 부른다. 

- plt.scatter 함수로 각각 x, y의 값들을 지정해준다.

- x, y가 어떤 특성을 가지는지 작성후 plt.show()로 산점도를 그린다.
    - 여기서 x축은 길이, y축은 무게를 뜻한다.

![1-3 산점도_1](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(3)%20%EC%82%B0%EC%A0%90%EB%8F%84_1.png)

- 산점도를 보면 데이터의 특성에 따라서 산점도가 그려진 것을 볼 수 있다.
- 위 산점도 그래프처럼 일직선에 가까운 형태로 나타나는 경우를 `선형(linear)`적이라고 말한다. 

```python
smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]
```

- 다른 데이터 특성 리스트이다.
    - ! 처음 작성할 때 임포트 하여 패키지를 불러와야 하는데 불러오지 않았다. 이유는 한번 임포트된 패키지는 그 파일 안에서 다시 임포트를 하지 않아도 이미 패키지를 불러온 상태이기 때문에 다시 불러오지 않아도 된다. 만약 연결이 끊긴 상태라면 다시 임포트를 해야한다.

```python
plt.scatter(bream_length, bream_weight)
plt.scatter(smelt_length, smelt_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

- 이번에는 다른 두 개의 데이터의 산점도를 그리기 위해 plt.scatter 함수로 x, y의 값들을 각각 입력해준다.


![1-6 산점도_2](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(6)%20%EC%82%B0%EC%A0%90%EB%8F%84_2.png)

- 맷플롯립은 2개의 데이터로 산점도를 그리게 되면 색깔로 구분해서 나타낸다.

-------------------
#### k-최근접 이웃 알고리즘을 이용한 데이터 구분

k-최근접 이웃 알고리즘
- 어떤 데이터에 대한 답을 구할 때 주위의 다른 데이터를 보고 다수를 차지하는 것을 정답으로 사용한다.

알고리즘을 이용하여 두 개의 데이터를 구분하고 분류하기 위해 다음의 단계로 진행한다.

```python
length = bream_length+smelt_length
weight = bream_weight+smelt_weight
```

- k-최근접 이웃 알고리즘을 이용하여 데이터를 구분하기 위해 먼저 두개의 데이터를 하나로 만들어준다.
- 위 코드처럼 두 리스트를 더하면 하나의 리스트로 만들어진다.

```python
fish_data = [[l, w] for l, w in zip(length, weight)]
```

- 현재 알고리즘에서 사용할 머신러닝 패키지는 `사이킷런(sckit-learn)`이다. 사이킷런을 사용하려면 리스트를 세로 방향으로 늘어뜨린 2차원 리스트로 만들어줘야한다.

- zip()함수와 for문을 이용하여 리스트에서 데이터를 하나씩 반환하여 2차원 리스트로 만들어준다.
    - zip()함수는 나열된 리스트 각각에서 하나씩 원소를 반환하는 함수이다.
    - 여기서 l, w는 length, weight의 리스트에서 원소를 하나씩 꺼내어 각각 할당한다.

![1-9 2차원 리스트 출력](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(9)%202%EC%B0%A8%EC%9B%90%20%EB%A6%AC%EC%8A%A4%ED%8A%B8%20%EC%B6%9C%EB%A0%A5%EB%AC%BC.png)

- 위와 같이 2차원 리스트를 출력해보면 l, w가 하나의 원소로 구성된 리스트가 만들어진 것을 확인할 수 있다.

![1-10 정답지 출력](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(10)%20%EC%A0%95%EB%8B%B5%EC%A7%80%20%EB%A7%8C%EB%93%A4%EA%B8%B0.png)

- 분류하기 앞서 머신러닝이 데이터를 구분하는 규칙을 알기 위해서는 정답 데이터가 필요하다.
- 만약 정답 데이터가 없다면 데이터들의 상관관계를 모르기 때문에 알 수가 없다. 그렇기 때문에 정답 데이터를 만들어주어야 한다.
- 앞서 만든 2차원 리스트에서 첫번째 데이터를 1, 두번째 데이터를 0이라고 지정하고 정답 데이터를 만들어 준다. 
- 첫번째 데이터는 35개, 두번째 데이터는 14개 이므로 각각 횟수민큼 곱셈을 해준다.

![1-11 사이킷런](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(11)%20%EC%82%AC%EC%9D%B4%ED%82%B7%EB%9F%B0%20%ED%8C%A8%ED%82%A4%EC%A7%80%20%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0.png)

- 이제 사이킷런 패키지에서 k-최근접 이웃 알고리즘을 구현한 클래스인 KNeightborsClassifier를 임포트한다.
- 여기서 패키지나 모듈 전체를 임포트하지 않고 특정 클래스만 임포트하려면 from ~ inport 구문을 사용한다.

![1-12 정답지 출력](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(12)%20%EC%9E%84%ED%8F%AC%ED%8A%B8%ED%95%9C%20%ED%81%B4%EB%9E%98%EC%8A%A4%20%EA%B0%9D%EC%B2%B4%20%EB%A7%8C%EB%93%A4%EA%B8%B0.png)

- 임포트한 KNeightborsClassifier 클래스의 객체를 먼저 만든다.
- 만든 객체에 2차원 리스트와 정답 데이터를 전달하여 원하는 데이터(예시에서는 도미)를 찾기 위한 기준을 학습시킨다.
- 이러한 과정을 머신러닝에서 `훈련(training)`이라고 부른다.
    - 모델에 데이터를 전달하여 규칙을 학습하는 과정을 *훈련*이라고 한다.
    - 사이킷런 패키지에선 fit() 메서드가 훈련 역할을 한다.

![1-13 알고리즘 훈련](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(13)%20%EC%A3%BC%EC%96%B4%EC%A7%84%20%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%20%ED%9B%88%EB%A0%A8.png)
- fit() 메서드를 가지고 주어진 데이터로 알고리즘을 훈련한다.
- 사이킷런에서 모델을 평가하는 메서드는 score() 이다.
- score() 메서드는 0에서 1 사이의 값을 반환하는데 1은 모든 데이터를 정확히 맞혔다는 것을 나타낸다.

![1-14 모델 평가](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(14)%20%ED%9B%88%EB%A0%A8%EB%90%9C%20%EB%AA%A8%EB%8D%B8%20%ED%8F%89%EA%B0%80.png)
- 1이 나온 것을 보아 데이터의 답을 정확히 맞힌 것을 알 수 있다.
- 이 값을 `정확도(accuracy)`라고 부른다.

-------------------
#### k-최근접 이웃 알고리즘

k-최근접 이웃 알고리즘은 다시 말하지만 어떤 데이터에 대한 답을 구할 때 주위의 다른 데이터를 보고 다수를 차지하는 것을 정답으로 사용한다.

![1-15 산점도_3](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(15)%20k-%EC%B5%9C%EA%B7%BC%EC%A0%91%20%EC%9D%B4%EC%9B%83%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%20%EC%82%B0%EC%A0%90%EB%8F%84.png)

- 만약 위의 산점도에서 삼각형은 어디의 데이터로 판단할 것인지 알고 싶다.
- k-최근접 이웃 알고리즘은 삼각형 주위에 파란 동그라미 데이터가 많기 때문에 동그라미 데이터로 판단할 것이다.

![1-16 예상 결과 판단](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(16)%20%EC%98%88%EC%83%81%20%EA%B2%B0%EA%B3%BC.png)

- 예상과 같이 파란 동그라미 데이터로 인식한다.
- 여기서 predict() 메서드는 새로운 데이터의 정답을 예측한다.
- 앞서 fit() 메서드와 마찬가지로 리스트의 리스트 즉 2차원 리스트로 전달해야 한다. 그래서 predict() 메서드 안의 값을 리스트로 2번 감싸주었다.
- 이렇게 생각하면 k-최근접 이웃 알고리즘을 위해 필요한 것은 데이터를 모두 가지고 있는게 전부이다.
- 새로운 데이터에 대해 예측할 때는 가장 가까운 직선거리에 어떤 데이터가 있는지를 찾기만 하면 되기 때문이다.
- 하지만 이러한 특징 때문에 데이터가 아주 많은 경우는 데이터가 크고, 메모리가 많이 필요한데다 직선거리를 계산하는 데도 많은 시간이 걸리는 단점이 있어 알고리즘을 선택하는데 생각을 해야한다.

![1-17 사이킷런 x값](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(17)%20%EC%82%AC%EC%9D%B4%ED%82%B7%EB%9F%B0%20x%EA%B0%92.png)

- 지금 사용하는 사이킷런의 KNeighborsClassifier 클래스도 마찬가지이다. 
- 이 클래스는 _fix_X 속성에 전달한 fish_data를


![1-18 사이킷런 y값](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(18)%20%EC%82%AC%EC%9D%B4%ED%82%B7%EB%9F%B0%20y%EA%B0%92.png)

 - _y 속성에는 fish_target을 가지고 있다.
 - 값들을 보면 k-최근접 이웃 알고리즘은 무언가 훈련하는 것이 없다는 걸 알 수 있다.
 - fit() 메서드에 전달한 데이터를 모두 저장하고 있다가 새로운 데이터가 등장하면 가장 가까운 데이터를 참고하여 구분한다.

 ![1-19 사이킷런 변화한 값](/assets/images/post/2023-07-06-%5B1-3%5D/1-3-(19)%20%EB%A7%88%EC%A7%80%EB%A7%89%20%EA%B2%B0%EA%B3%BC%EA%B0%92.png)

 - k-최근접 알고리즘에서 새로운 데이터가 들어 왔을 때 가장 가까운 데이터를 참고하는 기준은 정할 수 있다.
 - 우리가 사용하는 클래스 KNeighborsClassifier의 기본값은 5이다.
 - 기본 값인 5에서 49로 변경하고 어떻게 예측하는지 확인해보면 1에 가까운 값을 출력한다.
 - 이미 데이터에서 49개중 35개 이상의 데이터가 1의 값을 가지고 있기 때문에 어떠한 값을 넣어도 지금과 같은 값을 출력할 것이다.
 
kn49로 값을 변경한 후 코드를 동작하려 했더니 error가 발생하여 코드가 동작되지 않음을 확인하였다.

 













