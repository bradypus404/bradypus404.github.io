---
layout: post
title: "[ML Study]ch03-1 k-최근접 이웃 회귀"
subtitle: 혼자 공부하는 머신러닝+딥러닝 [3-1]
date: 2023-07-12 09:01:00 +0900
author: Hyeonsu
categories: [Machine Learning]
tags: [회귀, k-최근접 이웃 회귀, 결정계수, 과대적합과 과소적합]
---

#### 1. k-최근접 이웃 회귀
---------------------------

지도학습 알고리즘은 분류와 **회귀**(regression) 두 가지로 크게 나뉜다.

`회귀`란 클래스 중 하나로 분류하는 것이 아닌 임의의 어떤 숫자를 예측하는 것으로 
<br>정해진 클래스가 없고 임의의 수치를 출력하고, 두 변수 사이의 상관 관계를 분석하는 방법이다.

`k-최근접 이웃 분류 알고리즘`은 예측하려는 샘플에 가장 가까운 샘플 k개 선택하고
<br>이 샘플들의 클래스를 확인하여 다수 클래스를 새로운 샘플의 클래스로 예측하는 것이다.

마찬가지로 `k-최근접 이웃 회귀 알고리즘`도 예측하려는 샘플에 가장 가까운 샘플 k개를 선택하지만 
<br>**회귀**이기에 이웃한 샘플의 타깃은 어떤 클래스가 아니라 임의의 수치가 된다.
<br>이웃 샘플의 수치를 사용해 새로운 샘플 X의 타깃을 예측하는 방법으로는 수치들의 평균을 구하는 것이 있다.
<br>
<br>**ex.** 이웃한 샘플의 타깃값이 각각 100, 80, 60이고 이의 평균인 80이 샘플 X의 예측 타깃값이 된다.

#### 2. 데이터 준비
---------------------------
**[농어 데이터를 이용해 사이킷런 회귀 모델 훈련을 해보자]**
<br>
<br>농어의 길이가 **특성**, 무게가 **타깃**으로 바로 넘파이 배열을 사용하여 시작한다.
<br>

```python
import numpy as np
**perch_length = np.array([8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0,
        21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7,
        23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5,
        27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0,
        39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5,
        44.0])
perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,
        115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,
        150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,
        218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,
        556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,
        850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,
        1000.0])**
```

하나의 특성을 사용하기 때문에 특성 데이터를 **x축**에 놓고 타깃 데이터를 **y축**에 놓는다.
<br>맷플롯립을 임포트하고 **scatter ()** 함수를 사용해 산점도를 그려보자.
<br>

```python
import matplotlib.pyplot as plt
plt.scatter(perch_length, perch_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

![scatter](/assets/images/post/2023-07-13-[3-1]/ch03-1(1).png)
_농어의 길이가 커짐에 따라 무게도 늘어남을 볼 수 있다._
<br>
<br>

**[농어 데이터를 훈련세트와 테스트 세트를 나눠 실행해보자]**
<br>
<br>이는 **train_test_split ()** 함수를 사용해 나눌 것이고, random_state는 **random_state = 42**로 지정해준다.
<br>

```python
from sklearn.model_selection import train_test_split
train_input, test_input, train_target, test_target = train_test_split(perch_length, perch_weight, random_state=42)
```

훈련세트는 **2차원 배열**이여야 한다.
<br>perch_length가 1차원 배열이기 때문에 이를 나눈 **train_input**, **test_input**도 1차원 배열이다.
<br>1개의 열이 있는 2차원 배열로 변경해준다.
    
![array1](/assets/images/post/2023-07-13-[3-1]/ch03-1(2).png)
    
![array2](/assets/images/post/2023-07-13-[3-1]/ch03-1(3).png)
    

파이썬에서  1차원 배열의 크기는 원소가 1개인 튜플로 나타낸다.
<br>2차원 배열로 만들기 위해 억지로 **하나의 열을 추가**해서 배열의 크기가 (3, 1)로 된다.
<br>넘파이 배열은 크기를 바꿀 수 있는 **reshape ()** 메서드를 제공한다.
<br>
<br>

**[(4,  ) 배열을 (2, 2) 크기로 변경해보자]**
<br>

```python
test_array = np.array([1,2,3,4])
print(test_array.shape)
```

![(4, )](/assets/images/post/2023-07-13-[3-1]/ch03-1(4).png)
_test array는 (4,  ) 배열임을 확인한다._
<br>

```python
test_array = test_array.reshape(2, 2)
print(test_array.shape)
```
    
![(2, 2)](/assets/images/post/2023-07-13-[3-1]/ch03-1(5).png)
_reshape () 메서드는 바꾸려는 배열의 크기를 지정할 수 있다._
<br>
<br>

> reshape () 메서드는 크기가 바뀐 새로운 배열을 반환할 때 지정한 크기가 원본 배열에 있는 원소의 개수와 다르면 에러가 발생한다.
> ![reshapeerror](/assets/images/post/2023-07-13-[3-1]/ch03-1(6).png)

<br>

**[train_input과 test_input을 2차원 배열로 바꿔보자]**
<br>
<br>train_input의 크기는 (42,  )이고, (42, 1)로 바꾸려면 **train_input.reshape(42, 1)**과 같이 사용한다.
넘파이는 배열의 크기 자동 지정하는 기능 제공하므로, 크기에 -1 지정하면 나머지 원소 개수로 모두 채우라는 의미이다.
<br>
<br>**ex.** `train_input.reshape(-1, 1)`의 뜻은 
<br>&emsp;&emsp;첫 번째 크기를 나머지 원소 개수로 채우고, 두 번째 크기를 1로 하는 것이다.

```python
trai_input = train_input.reshape(-1, 1)
test_ninput = test_input.reshape(-1, 1)
print(train_input.shape, test_input.shape)
```
![reshape(-1, 1)](/assets/images/post/2023-07-13-[3-1]/ch03-1(7).png)
_reshape(-1, 1)과 같이 사용하면 배열의 전체 원소 개수를 보기에 편하다._


#### 3. 결정계수(R^2)
---------------------------



#### 4. 과대적합 vs 과소적합
---------------------------




#### 5. 회귀 문제 다루기
---------------------------