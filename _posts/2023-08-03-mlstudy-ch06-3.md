---
layout: post
title: "[ML Study]ch06-3 주성분 분석"
subtitle: 
date: 2023-08-03 09:02:00 +0900
author: Jinha_k
categories: [Machine Learning]
tags: [Dimensionality Reduction, Principal Component Analysis, Explained Variance]
---
<body>
    <img
    src="/assets/images/post/book_banner.jpg"
    align="right"
    width="20%"
    height="27.2%"
    />
    <br><br>
    <p>본 포스팅 한빛미디어의 <a href="https://product.kyobobook.co.kr/detail/S000001810330"><혼자공부하는 머신러닝+딥러닝(박해선 저)></a>를 요약 정리했습니다.</p>
</body>
<br>

## 차원 축소
-------------
차원 축소란 데이터가 가진 속성을 특성(Feature)라고 부르는데 이런 특성을 차원이라고 부른다. 차원 축소는 데이터를 가장 잘 나타내는 일부 특성을 선택하여 데이터 크기를 줄이고 지도 학습 모델의 성능을 향상시킬 수 있다.

### 주성분 분석
주성분 분석(Principal component Analysis, PCA)는 차원 축소 알고리즘으로 다차원 데이터의 차원을 축소하면서 데이터의 변동성을 최대한 보존하는 기법이다. 이를 통해 데이터를 더 낮은 차원으로 표현하면서 중요한 정보를 유지할 수 있다.

**PCA 과정**<br>
1. 데이터 센터링
2. 최적화 문제 정의
3. 최적화 문제 해결
4. 주축 정렬
5. PCA로 변환 및 복원

**주성분 분석의 한계**<br>
- 데이터가 가우시안 분포라는 것을 가정하여 가우시안 분포가 아닌 자료에 적용하기 어렵다.
- 분류 문제를 위해 제작된게 아니기 때문에 분류 성능 향상을 보장받지 못한다.

#### PCA 클래스
사이킷런은 sklearn.decomposition 모듈 아래 PCA 클래스로 주성분 분석 알고리즘을 제공한다. PCA 클래스 객체를 만들 때 c_components 매개변수에 주성분의 개수를 정해야 한다. 

```python
class sklearn.decomposition.PCA(n_components=None, *, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', n_oversamples=10, power_iteration_normalizer='auto', random_state=None)
```
- PCA 클래스는 데이터의 특이값 분해를 사용해 선형 차원 축소로 데이터를 저차원 공간에 투영한다. 입력데이터는 중앙에 위치하지만 SVD를 적용하기 전에 각 특징에 대해 스케일링되지 않는다.
- 입력 데이터의 모양과 추출할 구성 요소의 수에 따라 전체 SVD의 LAPACK 구현 쏘는 Halko 등의 방법에 따른 무작위로 잘린 SVD를 사용한다.
> 특잇값 분해(Singular Value Decomposition, SVD)는 행렬을 세 개의 행렬의 곱으로 분해하는 기법이고 차원 축소할 때 사용한다.

`inverse_transform()` 메서드를 이용하여 데이터를 복원할 수 있다.

### 설명된 분산
설면된 분산(Explained Variance)은 주성분이 원본 데이터의 분산을 얼마나 잘 나타내는지를 기록한 값이다. PCA 클래스의 explained_variance_ratio에 각 주성분의 설명된 분산 비율이 기록되어 있고 첫번째 주성분의 설명된 분산이 가장 크다.